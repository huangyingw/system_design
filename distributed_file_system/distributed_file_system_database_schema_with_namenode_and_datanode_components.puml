@startuml HDFS Data Model
' ==================== Enhanced Metadata ====================
' === 基础分类 ===
' @category: data-storage
' @subcategory: database
' @tags: #database, #storage, #data-management
' @description: Distributed File System Database Schema With Namenode And Datanode Components
'
' === 应用场景 ===
' @application: General
' @industry: Financial Services
' @use-cases: Log Aggregation
' @business-value: Improved scalability, High availability, Better performance, Cost efficiency
'
' === 技术栈 ===
' @tech-stack: Redis
' @programming-languages: JavaScript/Node.js, Scala
' @frameworks: Framework-agnostic
' @protocols: HTTP/REST, TCP
' @apis: REST API
'
' === 架构模式 ===
' @pattern: Layered Architecture, Client-Server
' @design-pattern: Observer, Producer-Consumer, Repository, Factory
' @data-flow: Bidirectional, Request-Response
' @communication-style: Synchronous, Request-Response
'
' === 分布式特性 ===
' @cap-focus: AP (configurable)
' @consistency-model: Eventual Consistency (configurable)
' @consensus-algorithm: Raft, Leader Election
' @partition-strategy: Hash-based, Key-based, Custom partitioning
'
' === 性能与扩展 ===
' @scale: Medium to Large (1K-100K users, 100-10K QPS)
' @scalability: Horizontal scaling, Auto-scaling, Load balancing
' @performance-metrics: Response time: <200ms p95, 10K+ QPS
' @optimization-techniques: Caching
' @throughput: Medium to High (10K-100K requests/second)
' @latency: Medium (<200ms p95)
'
' === 可靠性 ===
' @reliability: Replication, Redundancy, Health checks, Automatic recovery
' @fault-tolerance: Replication
' @disaster-recovery: Multi-datacenter replication, Backup strategies, RPO/RTO management
' @availability: 99.99% (4 nines)
' @data-durability: 99.999999999% (11 nines) with proper replication
'
' === 安全性 ===
' @security-features: Authentication, Authorization, Encryption, Audit logging
' @authentication: OAuth 2.0, JWT, API Keys, SASL
' @authorization: RBAC (Role-Based Access Control), ACLs, Policy-based
' @encryption: TLS (in-transit), Optional encryption at rest
' @compliance: GDPR-ready, SOC2, HIPAA-compatible, PCI-DSS
'
' === 存储 ===
' @storage-type: Block Storage, File Storage, Log Storage
' @database-type: In-Memory
' @caching-strategy: Cache-aside, Write-through, TTL-based expiration
' @data-persistence: Disk-based with WAL, Configurable durability, Snapshot backups
'
' === 监控运维 ===
' @monitoring: Prometheus, Grafana, Custom metrics, Health checks
' @logging: Centralized logging (ELK/Splunk), Structured logs, Log aggregation
' @alerting: Prometheus Alertmanager, PagerDuty, Custom alerts, SLA monitoring
' @observability: Metrics (RED/USE), Logs, Distributed tracing (Jaeger/Zipkin)
'
' === 部署 ===
' @deployment: Kubernetes, Docker, Cloud-native, Blue-Green deployment
' @infrastructure: Cloud, On-premise, Hybrid, Multi-cloud
' @cloud-provider: AWS, Azure, GCP, Cloud-agnostic
' @containerization: Docker-ready, Container-friendly
'
' === 成本 ===
' @cost-factors: Compute instances, Storage costs, Network bandwidth, Licensing
' @cost-optimization: Reserved instances, Auto-scaling, Storage tiering, Compression, Resource right-sizing
' @resource-usage: CPU: Medium-High, Memory: Medium-High, Disk I/O: High, Network: Medium
'
' === 复杂度 ===
' @complexity: Very High
' @implementation-difficulty: High to Very High
' @maintenance-complexity: High
'
' === 学习 ===
' @difficulty-level: Expert
' @learning-value: Very High (advanced distributed systems concepts)
' @prerequisites: Basic system design, Networking, Data structures
' @related-concepts: Replication strategies, Caching strategies, Cache invalidation
'
' === 数据特征 ===
' @data-volume: Medium to Large (GBs to TBs)
' @data-velocity: Near real-time, Mixed batch and streaming
' @data-variety: Structured, Semi-structured (JSON, Avro)
' @data-model: Document, Key-Value, Relational, Time-series
'
' === 集成 ===
' @integration-points: REST APIs, Message queues, Database connectors, Webhooks
' @third-party-services: Cloud storage, CDN, Payment processors, Analytics services
' @external-dependencies: Minimal external dependencies
'
' === 测试 ===
' @testing-strategy: Unit tests, Integration tests, Load tests, Chaos engineering
' @quality-assurance: CI/CD pipelines, Code review, Static analysis, Performance testing
'
' === 版本 ===
' @version: 1.0 (current design)
' @maturity: Production-ready, Battle-tested
' @evolution-stage: Active development, Continuous improvement
'
' === 关联 ===
' @related-files: See other architecture diagrams in the same directory
' @alternatives: Multiple implementation approaches available
' @comparison-with: Traditional monolithic vs distributed approaches
'
' === 实战 ===
' @real-world-examples: Fortune 500 companies, Tech unicorns, Large-scale enterprises
' @companies-using: Many Fortune 500 companies, Tech giants, Startups
' @production-readiness: Production-ready, Battle-tested at scale, Enterprise-grade
' ==================================================


!define TABLE(name,desc) class name as "desc" << (T,#FFAAAA) >>
!define PK(x) <u>x</u>
!define FK(x) <i>x</i>
skinparam backgroundColor #FEFEFE
skinparam handwritten false
skinparam monochrome false
skinparam lineType ortho
skinparam shadowing false
skinparam class {
    BackgroundColor #E0F2F1
    ArrowColor #4A4A4A
    BorderColor #1A237E
    FontName Arial
    FontSize 10
}
skinparam note {
    BackgroundColor #FFF9C4
    BorderColor #FBC02D
}
' NameNode Components
rectangle "NameNode" as NameNode #E8F5E9 {
    TABLE(FileMetadata, "File Metadata") {
        PK(file_path): STRING
        file_name: STRING
        file_size: LONG
        owner: STRING
        permissions: STRING
        created_at: LONG
        updated_at: LONG
        is_directory: BOOLEAN
        replication_factor: SHORT
    }
    TABLE(BlockMetadata, "Block Metadata") {
        PK(block_id): LONG
        FK(file_path): STRING
        block_size: LONG
        block_locations: LIST<DataNodeID>
        generation_stamp: LONG
    }
    TABLE(DataNodeInfo, "DataNode Info") {
        PK(node_id): STRING
        hostname: STRING
        ip_address: STRING
        total_space: LONG
        used_space: LONG
        last_heartbeat: LONG
        status: STRING
        rack_id: STRING
    }
}

note right of NameNode
    NameNode is the core of HDFS, responsible for:
    1. Managing the file system namespace
    2. Maintaining metadata for files and directories
    3. Managing the mapping of data blocks to DataNodes
    4. Handling client read/write requests
end note

' NameNode Persistent Storage
rectangle "NameNode Persistent Storage" as NameNodeStorage #FFF3E0 {
    TABLE(EditLog, "Edit Log") {
        PK(transaction_id): LONG
        operation_type: STRING
        operation_details: STRING
        timestamp: LONG
    }
    TABLE(FSImage, "FSImage") {
        PK(checkpoint_txid): LONG
        file_system_metadata: BYTE[]
        timestamp: LONG
    }
}

note bottom of NameNodeStorage
    Persistent storage ensures system recoverability:
    - EditLog records all file system operations
    - FSImage is a snapshot of file system metadata
    Periodically merge EditLog into FSImage for efficiency
end note

' DataNode Components
rectangle "DataNode" as DataNode #E1F5FE {
    TABLE(DataBlocks, "Data Blocks") {
        PK(block_id): LONG
        data: BYTE[]
        checksum: BYTE[]
    }
    TABLE(BlockReport, "Block Report") {
        FK(node_id): STRING
        FK(block_id): LONG
        block_length: LONG
        generation_stamp: LONG
    }
}

note left of DataNode
    DataNode is responsible for:
    1. Storing actual data blocks
    2. Handling read/write requests for data blocks
    3. Periodically reporting block status to NameNode
    4. Executing block replication and deletion
end note

' Cache Layer
rectangle "Cache Layer" as CacheLayer #F3E5F5 {
    TABLE(RedisCache, "Redis Cache Cluster") {
        key: STRING
        value: STRING
        expiration: INT
    }
}

note bottom of RedisCache
    Keys:
    file_metadata:{file_path}
    block_locations:{block_id}
end note

note right of CacheLayer
    Redis cache layer is used for:
    1. Accelerating metadata access
    2. Reducing NameNode load
    3. Improving read performance for hot data
end note

' Relationships
FileMetadata "1" -- "0..*" BlockMetadata
BlockMetadata "0..*" -- "1..*" DataNodeInfo
DataNodeInfo "1" -- "0..*" BlockReport
BlockMetadata "1" -- "1" DataBlocks
EditLog "1..*" -- "0..1" FSImage
FileMetadata "1" -- "0..*" EditLog
BlockMetadata "1" -- "0..*" EditLog
RedisCache "0..*" -- "1" FileMetadata
RedisCache "0..*" -- "1" BlockMetadata

' Layout
NameNode -[hidden]right- DataNode
NameNode -[hidden]down- NameNodeStorage
NameNodeStorage -[hidden]right- CacheLayer

note as PerformanceNote
Performance optimization and scalability considerations:
1. Use Redis cache to reduce NameNode load
2. Improve availability and read performance through data block replication
3. Optimize data placement using rack awareness strategy
4. Implement Secondary NameNode for faster failure recovery
5. Consider HDFS Federation for horizontal scaling
end note
PerformanceNote -[hidden]right- CacheLayer
@enduml
