@startuml
skinparam backgroundColor #D3D3D3

package "Spark on Kubernetes Application" #LightYellow {
    [Driver Program\n(Scala, Java, Python, R)] as Driver
        [SparkContext\n(Scala, Java, Python, R)] as SC
        [RDD Operations\n(Scala, Java, Python, R)] as RDDOps
        [DAG Scheduler\n(Scala)] as DAG
        [Task Scheduler\n(Scala)] as TS
}

package "Kubernetes Cluster" #LightGreen {
        [Kubernetes Master\n(Java, Scala)] as K8sMaster
        [Kubernetes API] as K8sAPI
    }

package "Kubernetes Worker Node 1" #LightBlue {
        [Pod 1\n(Kubernetes)] as Pod1
        [Executor 1\n(Scala, Java, Python, R)] as E1
        [Cache 1] as C1
    frame "Logical Data Processing" #Pink {
        [Map Task 1.1\n(Scala, Java, Python, R)] as MT11
        [Reduce Task 1.2\n(Scala, Java, Python, R)] as RT12
    }
}

package "Kubernetes Worker Node 2" #LightBlue {
        [Pod 2\n(Kubernetes)] as Pod2
        [Executor 2\n(Scala, Java, Python, R)] as E2
        [Cache 2] as C2
    frame "Logical Data Processing" #Pink {
        [Map Task 2.1\n(Scala, Java, Python, R)] as MT21
        [Reduce Task 2.2\n(Scala, Java, Python, R)] as RT22
    }
}

    [Final Reduce and Merge\n(Scala, Java, Python, R)] as FinalReduce

database "Data Storage System\n(Java)" as Storage #LightCoral {
        [HDFS\n(Java)]
        [Elasticsearch]
        [Other Sources] as Others
    }

Driver --> SC : Use
SC --> RDDOps : Data Transformations
RDDOps --> DAG : Convert to DAG
SC --> TS : Submit Tasks
SC --> K8sAPI : Deploy Driver/Executors
DAG --> TS : Execution Planning
TS --> K8sAPI : Request Executors
K8sMaster --> Pod1 : Schedule Pod
K8sMaster --> Pod2 : Schedule Pod
Pod1 --> E1 : Run Executor
E1 --> C1 : Data Caching
E1 --> MT11 : Execute Map Task
MT11 --> RT12 : Followed by Reduce Task
Pod2 --> E2 : Run Executor
E2 --> C2 : Data Caching
E2 --> MT21 : Execute Map Task
MT21 --> RT22 : Followed by Reduce Task
RT12 --> FinalReduce : Send Results
RT22 --> FinalReduce : Send Results
FinalReduce --> Storage : Final Output

note right of RT12
  Reduce Task 1.2:
  - Performs local reduce operations on Node 1
  - Part of the distributed reduce phase
end note

note right of RDDOps
  RDD Operations include:
  - Map
  - Reduce
  - Filter
  - Join
  - etc.
end note

note right of DAG
  DAG (Directed Acyclic Graph) represents:
  - Data processing steps and their dependencies
  - Optimizes task execution
  - Provides a fault-tolerance mechanism
  - No cyclic dependencies in the workflow
  - Basis for execution planning and optimization
end note

note right of Elasticsearch
  Elasticsearch is used for:
  - Full-text Search and Complex Queries
  - Real-time Analysis and Dashboards
  - Log and Event Data Analysis
  - Big Data Integration
  - Data Enrichment
end note

note top of C1
  Cache for Accelerating Data Access
  Supports Various Persistence Levels
end note

note right of Storage
  External Persistent Storage System
  Provides Long-term Data Storage and Fault Tolerance
end note

note right of K8sMaster
  Kubernetes Master:
  - Manages the Kubernetes Cluster
  - Schedules and Orchestrates Pods
  - Provides Cluster Management Capabilities
end note

note right of E1
  Executors run in Kubernetes Pods
  Each Pod represents a Spark Executor
  Pods are managed by Kubernetes
  Executors perform Tasks and may have local Cache
end note

note right of FinalReduce
  Final Reduce and Merge:
  - Aggregates results from all Reduce Tasks
  - Performs final data merging and processing
  - Outputs the final result to the Data Storage System
end note

@enduml
