@startuml ' ==================== Metadata ====================
' ==================== Enhanced Metadata ====================
' === 基础分类 ===
' @category: distributed-systems
' @subcategory: message-queue
' @tags: #kafka, #message-queue, #event-streaming, #distributed-systems
' @description: Kafka Producer Consumer Detailed Structure
'
' === 应用场景 ===
' @application: General
' @industry: General, Enterprise
' @use-cases: Log Aggregation
' @business-value: Improved scalability, High availability, Better performance, Cost efficiency
'
' === 技术栈 ===
' @tech-stack: Kafka, ZooKeeper
' @programming-languages: Language-agnostic
' @frameworks: Framework-agnostic
' @protocols: HTTP/REST, TCP
' @apis: REST API
'
' === 架构模式 ===
' @pattern: Layered Architecture, Client-Server
' @design-pattern: Observer, Producer-Consumer, Repository, Factory
' @data-flow: Producer → Broker → Consumer
' @communication-style: Asynchronous, Synchronous
'
' === 分布式特性 ===
' @cap-focus: AP (Availability + Partition Tolerance)
' @consistency-model: Eventual Consistency (configurable)
' @consensus-algorithm: Raft, Leader Election
' @partition-strategy: Hash-based, Key-based, Custom partitioning
'
' === 性能与扩展 ===
' @scale: Large to Very Large (100K-10M users, 1K-100K QPS)
' @scalability: Horizontal scaling, Auto-scaling, Load balancing
' @performance-metrics: Throughput: 1M+ msg/s, Latency: <10ms p99
' @optimization-techniques: Batch processing, Compression, Sharding/Partitioning
' @throughput: Very High (1M+ messages/second)
' @latency: Low (<10ms p99)
'
' === 可靠性 ===
' @reliability: Replication, Redundancy, Health checks, Automatic recovery
' @fault-tolerance: Replication, Failover, Health monitoring, Graceful degradation
' @disaster-recovery: Multi-datacenter replication, Backup strategies, RPO/RTO management
' @availability: 99.9% (3 nines)
' @data-durability: 99.999999999% (11 nines) with proper replication
'
' === 安全性 ===
' @security-features: Authentication, Authorization, Encryption, Audit logging
' @authentication: OAuth 2.0, JWT, API Keys, SASL
' @authorization: RBAC (Role-Based Access Control), ACLs, Policy-based
' @encryption: TLS (in-transit), Optional encryption at rest
' @compliance: GDPR-ready, SOC2, HIPAA-compatible, PCI-DSS
'
' === 存储 ===
' @storage-type: Log Storage
' @database-type: Polyglot (SQL + NoSQL)
' @caching-strategy: Cache-aside, Write-through, TTL-based expiration
' @data-persistence: Disk-based with WAL, Configurable durability, Snapshot backups
'
' === 监控运维 ===
' @monitoring: Prometheus, Grafana, Custom metrics, Health checks
' @logging: Centralized logging (ELK/Splunk), Structured logs, Log aggregation
' @alerting: Prometheus Alertmanager, PagerDuty, Custom alerts, SLA monitoring
' @observability: Metrics (RED/USE), Logs, Distributed tracing (Jaeger/Zipkin)
'
' === 部署 ===
' @deployment: Kubernetes, Docker, Cloud-native, Blue-Green deployment
' @infrastructure: Cloud, On-premise, Hybrid, Multi-cloud
' @cloud-provider: AWS, Azure, GCP, Cloud-agnostic
' @containerization: Docker-ready, Container-friendly
'
' === 成本 ===
' @cost-factors: Compute instances, Storage costs, Network bandwidth, Licensing
' @cost-optimization: Reserved instances, Auto-scaling, Storage tiering, Compression, Resource right-sizing
' @resource-usage: CPU: Medium-High, Memory: Medium-High, Disk I/O: High, Network: Medium
'
' === 复杂度 ===
' @complexity: Medium
' @implementation-difficulty: Medium
' @maintenance-complexity: Medium
'
' === 学习 ===
' @difficulty-level: Intermediate
' @learning-value: Medium to High (practical system design)
' @prerequisites: Message queues, Pub-Sub pattern
' @related-concepts: CAP theorem, Data partitioning
'
' === 数据特征 ===
' @data-volume: Large (TBs)
' @data-velocity: Batch processing, Scheduled
' @data-variety: Avro
' @data-model: Document, Key-Value, Relational, Time-series
'
' === 集成 ===
' @integration-points: REST APIs, Message queues, Database connectors, Webhooks
' @third-party-services: Cloud storage, CDN, Payment processors, Analytics services
' @external-dependencies: Minimal external dependencies
'
' === 测试 ===
' @testing-strategy: Unit tests, Integration tests, Load tests, Chaos engineering
' @quality-assurance: CI/CD pipelines, Code review, Static analysis, Performance testing
'
' === 版本 ===
' @version: 1.0 (current design)
' @maturity: Production-ready, Battle-tested
' @evolution-stage: Active development, Continuous improvement
'
' === 关联 ===
' @related-files: See other architecture diagrams in the same directory
' @alternatives: Multiple implementation approaches available
' @comparison-with: Traditional monolithic vs distributed approaches
'
' === 实战 ===
' @real-world-examples: LinkedIn, Netflix, Uber, Airbnb
' @companies-using: LinkedIn, Netflix, Uber, Airbnb
' @production-readiness: Production-ready, Battle-tested at scale, Enterprise-grade
' ==================================================


skinparam backgroundColor #F5F5F5
skinparam packageStyle rectangle
allowmixing
skinparam linetype ortho

title Kafka Producer and Consumer Detailed Architecture

rectangle "Kafka System" {
    
    rectangle "Producer Components" as ProducerComponents {
        component "Producer" as Producer #87CEFA
        component "ProducerInterceptor" as ProducerInterceptor #87CEFA
        component "Serializer" as Serializer #87CEFA
        component "Partitioner" as Partitioner #87CEFA
        component "RecordAccumulator" as RecordAccumulator #87CEFA
        component "Sender" as Sender #87CEFA

        Producer -[#FF6347,thickness=2]-> ProducerInterceptor : 1
        ProducerInterceptor -[#FF6347,thickness=2]-> Serializer : 2
        Serializer -[#FF6347,thickness=2]-> Partitioner : 3
        Partitioner -[#FF6347,thickness=2]-> RecordAccumulator : 4
        RecordAccumulator -[#FF6347,thickness=2]-> Sender : 5
    }

    rectangle "Consumer Components" as ConsumerComponents {
        component "Consumer" as Consumer #FFA07A
        component "Coordinator" as Coordinator #FFA07A
        component "PartitionAssignor" as PartitionAssignor #FFA07A
        component "FetchManager" as FetchManager #FFA07A
        component "Deserializer" as Deserializer #FFA07A
        component "ConsumerInterceptor" as ConsumerInterceptor #FFA07A

        Consumer -[#4682B4,thickness=2]-> Coordinator : 1
        Coordinator -[#4682B4,thickness=2]-> PartitionAssignor : 2
        PartitionAssignor -[#4682B4,thickness=2]-> FetchManager : 3
        FetchManager -[#4682B4,thickness=2]-> Deserializer : 4
        Deserializer -[#4682B4,thickness=2]-> ConsumerInterceptor : 5
    }

    component "Broker" as Broker #98FB98

    Sender -[#FF6347,thickness=2]-> Broker : <color:#FF6347>6. Send messages</color>
    Broker -[#4682B4,thickness=2]-> FetchManager : <color:#4682B4>6. Deliver messages</color>
}

note right of Producer
  Initiates message production process
  <b>Bottleneck:</b> High message volume
  <b>Optimize:</b> Increase batch size, use async sends
end note

note right of ProducerInterceptor
  Intercepts and modifies messages
  <b>Bottleneck:</b> Complex interception logic
  <b>Optimize:</b> Keep interception logic simple
end note

note right of Serializer
  Converts messages to byte arrays
  <b>Bottleneck:</b> Inefficient serialization
  <b>Optimize:</b> Use efficient formats (e.g., Avro)
end note

note right of Partitioner
  Determines message partition
  <b>Bottleneck:</b> Uneven partition distribution
  <b>Optimize:</b> Implement custom partitioner if needed
end note

note right of RecordAccumulator
  Batches messages for efficiency
  <b>Bottleneck:</b> Memory usage for large batches
  <b>Optimize:</b> Fine-tune batch.size and linger.ms
end note

note right of Sender
  Sends batched messages to broker
  <b>Bottleneck:</b> Network I/O
  <b>Optimize:</b> Increase buffer.memory, use compression
end note

note left of Consumer
  Initiates message consumption process
  <b>Bottleneck:</b> Slow message processing
  <b>Optimize:</b> Increase consumer threads
end note

note left of Coordinator
  Manages consumer group membership
  <b>Bottleneck:</b> Frequent rebalances
  <b>Optimize:</b> Tune session.timeout.ms
end note

note left of PartitionAssignor
  Assigns partitions to consumers
  <b>Bottleneck:</b> Uneven partition assignment
  <b>Optimize:</b> Use appropriate assignment strategy
end note

note left of FetchManager
  Fetches messages from broker
  <b>Bottleneck:</b> Fetch size too small
  <b>Optimize:</b> Increase fetch.min.bytes
end note

note left of Deserializer
  Converts byte arrays back to messages
  <b>Bottleneck:</b> Inefficient deserialization
  <b>Optimize:</b> Use efficient deserialization methods
end note

note left of ConsumerInterceptor
  Intercepts and processes consumed messages
  <b>Bottleneck:</b> Complex interception logic
  <b>Optimize:</b> Keep interception logic simple
end note

note bottom of Broker
  Stores and manages message topics and partitions
  <b>Bottleneck:</b> Disk I/O, network bandwidth
  <b>Optimize:</b> Use SSDs, RAID, increase num.io.threads, network capacity
end note

@enduml
