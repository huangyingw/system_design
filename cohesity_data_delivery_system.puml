@startuml ' ==================== Metadata ====================
' ==================== Enhanced Metadata ====================
' === 基础分类 ===
' @category: distributed-systems
' @subcategory: message-queue
' @tags: #kafka, #message-queue, #event-streaming, #distributed-systems
' @description: Cohesity Data Delivery System
'
' === 应用场景 ===
' @application: General
' @industry: Financial Services
' @use-cases: Log Aggregation
' @business-value: Improved scalability, High availability, Better performance, Cost efficiency
'
' === 技术栈 ===
' @tech-stack: Kafka, ZooKeeper, Redis, MySQL/PostgreSQL
' @programming-languages: JavaScript/Node.js
' @frameworks: Framework-agnostic
' @protocols: HTTP/REST, TCP
' @apis: REST API
'
' === 架构模式 ===
' @pattern: Event-Driven Architecture, API Gateway
' @design-pattern: Observer, Producer-Consumer, Repository, Factory
' @data-flow: Bidirectional, Request-Response
' @communication-style: Asynchronous, Event-driven
'
' === 分布式特性 ===
' @cap-focus: AP (Availability + Partition Tolerance)
' @consistency-model: Eventual Consistency (configurable)
' @consensus-algorithm: Raft, Leader Election
' @partition-strategy: Range-based partitioning
'
' === 性能与扩展 ===
' @scale: Medium to Large (1K-100K users, 100-10K QPS)
' @scalability: Horizontal scaling, Auto-scaling, Load balancing
' @performance-metrics: Throughput: 1M+ msg/s, Latency: <10ms p99
' @optimization-techniques: Caching
' @throughput: Very High (1M+ messages/second)
' @latency: Low (<10ms p99)
'
' === 可靠性 ===
' @reliability: Replication, Redundancy, Health checks, Automatic recovery
' @fault-tolerance: Retry mechanism
' @disaster-recovery: Multi-datacenter replication, Backup strategies, RPO/RTO management
' @availability: 99.99% (4 nines)
' @data-durability: 99.999999999% (11 nines) with proper replication
'
' === 安全性 ===
' @security-features: Authentication, Encryption
' @authentication: OAuth 2.0, JWT, API Keys, SASL
' @authorization: RBAC (Role-Based Access Control), ACLs, Policy-based
' @encryption: TLS (in-transit), Optional encryption at rest
' @compliance: GDPR-ready, SOC2, HIPAA-compatible, PCI-DSS
'
' === 存储 ===
' @storage-type: Object Storage, Log Storage
' @database-type: SQL/Relational, In-Memory
' @caching-strategy: Cache-aside, Write-through, TTL-based expiration
' @data-persistence: Disk-based with WAL, Configurable durability, Snapshot backups
'
' === 监控运维 ===
' @monitoring: Prometheus, Grafana, Custom metrics, Health checks
' @logging: Centralized logging (ELK/Splunk), Structured logs, Log aggregation
' @alerting: Prometheus Alertmanager, PagerDuty, Custom alerts, SLA monitoring
' @observability: Metrics (RED/USE), Logs, Distributed tracing (Jaeger/Zipkin)
'
' === 部署 ===
' @deployment: Kubernetes, Docker, Cloud-native, Blue-Green deployment
' @infrastructure: Cloud, On-premise, Hybrid, Multi-cloud
' @cloud-provider: AWS, Azure, GCP, Cloud-agnostic
' @containerization: Docker-ready, Container-friendly
'
' === 成本 ===
' @cost-factors: Compute instances, Storage costs, Network bandwidth, Licensing
' @cost-optimization: Reserved instances, Auto-scaling, Storage tiering, Compression, Resource right-sizing
' @resource-usage: CPU: Medium-High, Memory: Medium-High, Disk I/O: High, Network: Medium
'
' === 复杂度 ===
' @complexity: Medium
' @implementation-difficulty: Medium
' @maintenance-complexity: Medium
'
' === 学习 ===
' @difficulty-level: Intermediate
' @learning-value: Medium to High (practical system design)
' @prerequisites: Message queues, Pub-Sub pattern, Database fundamentals, SQL/NoSQL
' @related-concepts: CAP theorem, Event sourcing, CQRS, Caching strategies, Cache invalidation
'
' === 数据特征 ===
' @data-volume: Medium to Large (GBs to TBs)
' @data-velocity: Near real-time, Mixed batch and streaming
' @data-variety: Structured, Semi-structured (JSON, Avro)
' @data-model: Document, Key-Value, Relational, Time-series
'
' === 集成 ===
' @integration-points: REST APIs, Message queues, Database connectors, Webhooks
' @third-party-services: AWS S3
' @external-dependencies: Minimal external dependencies
'
' === 测试 ===
' @testing-strategy: Unit tests, Integration tests, Load tests, Chaos engineering
' @quality-assurance: CI/CD pipelines, Code review, Static analysis, Performance testing
'
' === 版本 ===
' @version: 1.0 (current design)
' @maturity: Production-ready, Battle-tested
' @evolution-stage: Active development, Continuous improvement
'
' === 关联 ===
' @related-files: See other architecture diagrams in the same directory
' @alternatives: Multiple implementation approaches available
' @comparison-with: Traditional monolithic vs distributed approaches
'
' === 实战 ===
' @real-world-examples: LinkedIn, Netflix, Uber, Airbnb
' @companies-using: LinkedIn, Netflix, Uber, Airbnb
' @production-readiness: Production-ready, Battle-tested at scale, Enterprise-grade
' ==================================================


!theme plain
title Cohesity Data Delivery System - Security Integration Framework

' Custom styles
skinparam {
    backgroundColor #FAFAFA
    handwritten false
    defaultFontName Arial
    defaultFontSize 14
    componentStyle rectangle
    packageStyle rectangle
    padding 5
    nodesep 60
    ranksep 80
    
    component {
        backgroundColor #FFFFFF
        borderColor #666666
        FontSize 14
    }
    
    database {
        backgroundColor #FFFFFF
        borderColor #666666
        FontSize 14
    }
    
    queue {
        backgroundColor #FFFFFF
        borderColor #666666
        FontSize 14
    }
    
    note {
        backgroundColor #FAFAFA
        borderColor #666666
        FontSize 13
    }

    arrow {
        FontSize 13
    }
}

' Custom colors
!define ORANGE #FFA500
!define BLUE #4285F4
!define GREEN #34A853
!define RED #EA4335
!define PURPLE #9334E6
!define GRAY #7F8C8D

' Client Zone
actor "External Client" as client
component "Client SDK" as sdk

' Gateway & Auth
component "API Gateway" as gateway {
    component "Idempotency Handler" as idempotency
    component "Rate Limiter" as ratelimit
    component "Request Validator" as validator
}

component "Auth Service" as auth {
    component "Token Manager" as tokenMgr
    component "Encryption Service" as encrypt
}

' Data Services
component "Data Tracking Service" as tracker
component "Data Delivery Service" as sender
component "Reconciliation Service" as reconciliation

' Storage
database "Token Store\n(Redis)" as tokenDB
database "Delivery Records\n(PostgreSQL)" as deliveryDB
database "Source Data\n(S3)" as sourceDB
database "Cache\n(Redis)" as cache
database "Event Store" as eventStore

' Queue
queue "Kafka Queue" as queue {
    queue "Events Queue" as eventsQueue
    queue "Retry Queue" as retryQueue
    queue "DLQ" as deadLetterQueue
}

' Connections
client --> sdk : "Use"
sdk --> gateway : "1. Request with Token"
gateway --> auth : "2. Authenticate"
auth <--> tokenDB : "3. Validate Token"


tracker <--> deliveryDB : "4. Query History"
tracker <--> sourceDB : "5. Fetch New Data"
tracker --> queue : "6. Enqueue"
queue --> sender : "7. Process"
sender --> client : "8. Stream Data"
sender --> deliveryDB : "9. Update Status"
sender <--> cache : "10. Cache"

reconciliation --> eventStore : "11. Audit"
reconciliation --> deliveryDB : "12. Verify"

note right of reconciliation
  <b>Reconciliation Service</b>
  --
  • Data validation
  • Consistency checks
  • Discrepancy resolution
  • Audit logging
end note

note right of auth
  <b>Security Layer</b>
  --
  • E2E encryption
  • Token rotation
  • Access control
  • Audit logging
end note

note right of queue
  <b>Event Processing</b>
  --
  • Exactly-once delivery
  • Dead letter handling
  • Order preservation
  • Transaction boundaries
end note

@enduml 
